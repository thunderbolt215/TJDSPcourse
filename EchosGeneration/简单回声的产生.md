# 简单回声的产生

## 问题背景

回声是有原始信号衰减后的多个延迟叠加而组成。回声用信号处理的延迟单元来生成。$x(n)$表示原始声音信号，$y(n)$表示叠加后的声音信号。则原始信号和它延迟了R个间隔的单个回声可以用如下差分方程表示：
$$
y(n)=x(n)+\alpha x(n-R),|\alpha|<1
$$
$\alpha$表示回声的衰减函数，上述差分方程可以用系统函数表示为：
$$
H(z)=1+\alpha z^{-R}
$$
实际上可认为是一个梳状滤波器，如图所示：

![Snipaste_2022-10-23_10-54-31](https://cdn.staticaly.com/gh/thunderbolt215/imagehosting@main/data/Snipaste_2022-10-23_10-54-31.5434wj3ba380.webp)

## 实验要求

- 采样量化：录制一段一定采样频率的语音数据，画出其语音信号波形，横轴标注为时间$t(s)$，纵轴标注为"幅度"。
- 对录制语音信号降低一倍采样率，进行抽取，画出抽取后的信号波形，横轴标注为时间$t(s)$， 纵轴为”幅度”，播放降低采样率后的语音信号。
- 设置回声延迟为0.4s，回声衰减60%，即$\alpha=0.4$，实现回声信号。

## 环境

本实验采用python语言编写，requirements如下：

```
librosa==0.9.2
matplotlib==2.2.3
numpy==1.21.6
soundfile==0.11.0
tqdm==4.26.0
```

解释器版本为`python 3.7`。

## 代码

```python
import pyaudio
import wave
from tqdm import tqdm
import matplotlib.pyplot as plt
import numpy as np
import librosa
import soundfile


def save_wave_file(filename, data):
    with wave.open(filename, 'wb') as wf:  # 打开文件
        wf.setnchannels(channels)  # 设置声道数量
        wf.setsampwidth(sampwidth)  # 设置样本宽度
        wf.setframerate(framerate)  # 设置帧速率
        wf.writeframes(b"".join(data))


def my_record(filename):
    pa = pyaudio.PyAudio()
    stream = pa.open(format=pyaudio.paInt16, channels=1,  # 创建
                     rate=framerate, input=True,
                     frames_per_buffer=num_samples)
    my_buf = []
    print("* recording starts")
    for count in tqdm(range(0, time * 8)):  # 控制录音时间
        string_audio_data = stream.read(num_samples)
        my_buf.append(string_audio_data)
    print("* done recording")

    save_wave_file(filename + ".wav", my_buf)
    stream.close()


def plot_wave(wavfilepath, title):
    plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签
    plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示符号
    # 打开WAV文档
    f = wave.open(wavfilepath, "rb")
    # 读取格式信息
    params = f.getparams()
    nchannels, sampwidth, framerate, nframes = params[:4]
    # nchannels通道数
    # sampwidth量化位数
    # framerate采样频率
    # nframes采样点数

    # 读取读取nframes个数据，返回字符串格式
    str_data = f.readframes(nframes)
    f.close()

    # 将波形数据转换为数组
    wave_data = np.frombuffer(str_data, dtype=np.short)
    # 赋值的归一化
    wave_data = wave_data * 1.0 / (max(abs(wave_data)))
    # 整合左声道和右声道的数据
    wave_data = np.reshape(wave_data, [nframes, nchannels])
    # 最后通过采样点数和取样频率计算出每个取样的时间
    time = np.arange(0, nframes) * (1.0 / framerate)

    # 录制的是单声道文件
    plt.figure()
    plt.plot(time, wave_data[:, 0])
    plt.xlabel("时间t(s)", fontsize=14)
    plt.ylabel("幅度", fontsize=14)
    plt.title(title, fontsize=14)
    plt.grid()  # 标尺

    plt.tight_layout()  # 紧密布局
    plt.show()


def playwav(wavfilepath):
    f = wave.open(wavfilepath, 'rb')
    params = f.getparams()
    nchannels, sampwidth, framerate, nframes = params[:4]
    p = pyaudio.PyAudio()
    stream = p.open(format=p.get_format_from_width(f.getsampwidth()), channels=f.getnchannels(),
                    rate=f.getframerate(), output=True)
    data = f.readframes(nframes)  # 读取数据

    print("* playing starts")
    for count in tqdm(range(0, time * 8)):
        stream.write(data)
        data = f.readframes(nframes)
    print("* done playing")
    stream.stop_stream()  # 停止数据流
    stream.close()
    p.terminate()  # 关闭 PyAudio


if __name__ == '__main__':
    # 参数设置
    framerate = 16000  # 帧速率
    num_samples = 2000  # 每个缓冲区的帧数
    channels = 1  # 声道
    sampwidth = 2  # 设置样本宽度
    time = 5  # 录制时长

    # 录制
    filepath = "origin.wav"
    my_record("origin")

    # 采样量化,输出波形
    origin_sr = librosa.get_samplerate(filepath)  # 原始采样率
    data_origin, _ = librosa.load(filepath, sr=origin_sr)  # 原始音频时间序列
    plot_wave(filepath, "原始音频")
    playwav(filepath)
    plt.show()

    # 降低一倍采样率
    data_downsample, _ = librosa.load(filepath, sr=origin_sr // 2)
    soundfile.write("downsample.wav", data_downsample, origin_sr // 2)
    plot_wave("downsample.wav", "降采样音频")
    playwav("downsample.wav")
    plt.show()

    # 回声计算
    length = len(data_origin)
    delay_time = 0.4  # 延迟时间
    decay = 0.4  # 回声衰减
    delay = int(delay_time / time * length)  # 延迟的序列单元数
    tmp1 = [data_origin[i] if i < length else 0 for i in range(0, delay + length)]
    tmp2 = np.roll(tmp1, delay)
    data_echos = list(np.array(tmp1) + np.array(tmp2))  # 计算回声音频序列
    soundfile.write("echos.wav", data_echos, origin_sr)
    plot_wave("echos.wav", "回声音频")
    playwav("echos.wav")
    plt.show()
```

其中对于实验要求步骤的说明作为注释写在代码当中，此处不再赘述。

## 实验结果

### 原始音频采样量化

原始音频保存为`origin.wav`，其时域波形如下：

![原始音频](https://cdn.staticaly.com/gh/thunderbolt215/imagehosting@main/data/原始音频.8aurn3imehw.webp)

### 降采样音频

降采样一倍后的音频保存为`downsample.wav`，时域波形如下：

![降采样音频](https://cdn.staticaly.com/gh/thunderbolt215/imagehosting@main/data/降采样音频.5i0pmk14jmk0.webp)

### 回声叠加

依据实验要求中的简单回声叠加公式(1)进行计算，得到回声音频保存为`echos.wav`，时域波形如下：

![回声音频](https://cdn.staticaly.com/gh/thunderbolt215/imagehosting@main/data/回声音频.4cacj3ozeh20.webp)

## 附件说明

附件文件夹experiment中放入了本次实验的代码和实验结果，具体说明如下：

| 文件             | 说明                 |
| ---------------- | -------------------- |
| Echos.py         | 源代码               |
| requirements.txt | 实验环境依赖         |
| origin.wav       | 原始音频文件         |
| 原始音频.png     | 原始音频时域波形     |
| downsample.wav   | 降采样音频文件       |
| 降采样音频.png   | 降采样音频时域波形   |
| echos.wav        | 回声叠加音频文件     |
| 回声音频.png     | 回声叠加音频时域波形 |

